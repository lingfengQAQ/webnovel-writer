#!/usr/bin/env python3
"""
ä¸Šä¸‹æ–‡åˆ†é¡µç®¡ç†ç³»ç»Ÿ (Context Manager)

æ ¸å¿ƒç†å¿µï¼š200ä¸‡å­—å°è¯´ä¸èƒ½æ¯æ¬¡éƒ½åŠ è½½å…¨éƒ¨è®¾å®šï¼Œéœ€è¦"æ»‘åŠ¨çª—å£"æœºåˆ¶ã€‚

åŠŸèƒ½ï¼š
1. æ ¹æ®å½“å‰ç« èŠ‚çš„ location å’Œ charactersï¼ŒåŠ¨æ€ç­›é€‰ç›¸å…³è®¾å®š
2. åˆ†å±‚åŠ è½½ï¼šæ ¸å¿ƒä¸Šä¸‹æ–‡ï¼ˆå¿…é¡»ï¼‰+ åœºæ™¯ä¸Šä¸‹æ–‡ï¼ˆæŒ‰éœ€ï¼‰+ å…¨å±€æ¦‚è§ˆï¼ˆæç®€ï¼‰
3. Token ä¼˜åŒ–ï¼šä» 50,000 Token å‹ç¼©åˆ° 3,500 Tokenï¼ˆèŠ‚çœ 93%ï¼‰
4. ç¼“å­˜æœºåˆ¶ï¼šé¿å…é‡å¤è®¡ç®—

ä½¿ç”¨æ–¹å¼ï¼š
  # ä¸ºç¬¬ 45 ç« æ„å»ºä¸Šä¸‹æ–‡
  python context_manager.py --chapter 45 --output .webnovel/context_cache.json

  # æŒ‡å®šä¸»è§’æ‰€åœ¨åœ°ç‚¹ï¼ˆå¯é€‰ï¼Œå¦åˆ™ä» state.json è¯»å–ï¼‰
  python context_manager.py --chapter 45 --location "è¡€ç…ç§˜å¢ƒ" --output context.json

  # Dry-run æ¨¡å¼ï¼ˆé¢„è§ˆ Token æ¶ˆè€—ï¼‰
  python context_manager.py --chapter 45 --dry-run

æ¶æ„è®¾è®¡ï¼š
  æ ¸å¿ƒä¸Šä¸‹æ–‡ï¼ˆCore Contextï¼‰- å¿…é¡»åŠ è½½
    â””â”€â”€ å½“å‰ç« èŠ‚å¤§çº²ï¼ˆæœ¬ç« ç›®æ ‡ã€å‡ºåœºè§’è‰²ã€çˆ½ç‚¹è®¾è®¡ï¼‰
    â””â”€â”€ ä¸»è§’å¡ï¼ˆç®€ç‰ˆï¼šå§“åã€å¢ƒç•Œã€é‡‘æ‰‹æŒ‡ã€æ ¸å¿ƒæ€§æ ¼ï¼‰
    â””â”€â”€ å‰ 2 ç« æ‘˜è¦ï¼ˆå„ 200 å­—ï¼‰

  åœºæ™¯ä¸Šä¸‹æ–‡ï¼ˆScene Contextï¼‰- æŒ‰éœ€åŠ è½½
    â””â”€â”€ å½“å‰åœ°ç‚¹è¯¦æƒ…ï¼ˆä» ä¸–ç•Œè§‚.md æå–å¯¹åº”ç« èŠ‚ï¼‰
    â””â”€â”€ å‡ºåœºè§’è‰²å¡ï¼ˆå®Œæ•´ç‰ˆï¼Œæœ€å¤š 5 ä¸ªï¼‰
    â””â”€â”€ ç›¸å…³ä¼ç¬”ï¼ˆstatus=æœªå›æ”¶ ä¸” æ¶‰åŠå½“å‰åœ°ç‚¹/è§’è‰²ï¼‰
    â””â”€â”€ ç›¸å…³ç‰©å“/æ‹›å¼ï¼ˆä¸»è§’å½“å‰æ‹¥æœ‰ + æœ¬ç« å¯èƒ½ç”¨åˆ°ï¼‰

  å…¨å±€æ¦‚è§ˆï¼ˆGlobal Overviewï¼‰- æç®€ç‰ˆ
    â””â”€â”€ ä¸–ç•Œè§‚éª¨æ¶ï¼ˆ500 Tokenï¼šåŠ¿åŠ›å…³ç³»å›¾ + åœ°ç†æ¡†æ¶ï¼‰
    â””â”€â”€ åŠ›é‡ä½“ç³»ï¼ˆ300 Tokenï¼šå¢ƒç•Œåˆ—è¡¨ + ä¸»è§’å½“å‰ä½ç½®ï¼‰
    â””â”€â”€ å…³é”®ä¼ç¬”æé†’ï¼ˆ100 Tokenï¼šæœªå›æ”¶ä¸”ç´§æ€¥çš„ï¼‰

Token é¢„ç®—åˆ†é…ï¼š
  - æ ¸å¿ƒä¸Šä¸‹æ–‡ï¼š1500 Token
  - åœºæ™¯ä¸Šä¸‹æ–‡ï¼š1500 Token
  - å…¨å±€æ¦‚è§ˆï¼š500 Token
  - æ€»è®¡ï¼š3500 Tokenï¼ˆçº¦ 2600 å­—ä¸­æ–‡ï¼‰
"""

import json
import os
import sys
import re
from pathlib import Path
from typing import Dict, List, Any, Optional

class ContextManager:
    """ä¸Šä¸‹æ–‡æ»‘åŠ¨çª—å£ç®¡ç†å™¨"""

    def __init__(self, project_root: str):
        self.project_root = Path(project_root)
        self.state_file = self.project_root / ".webnovel/state.json"
        self.outline_dir = self.project_root / "å¤§çº²"
        self.settings_dir = self.project_root / "è®¾å®šé›†"
        self.chapters_dir = self.project_root / "æ­£æ–‡"

        self.state = None
        self.token_budget = {
            "core": 1500,
            "scene": 1500,
            "global": 500
        }

    def load_state(self) -> bool:
        """åŠ è½½ state.json"""
        if not self.state_file.exists():
            print(f"âŒ çŠ¶æ€æ–‡ä»¶ä¸å­˜åœ¨: {self.state_file}")
            return False

        with open(self.state_file, 'r', encoding='utf-8') as f:
            self.state = json.load(f)

        return True

    def estimate_tokens(self, text: str) -> int:
        """ä¼°ç®—æ–‡æœ¬çš„ Token æ•°é‡ï¼ˆç²—ç•¥ï¼šä¸­æ–‡ 1.5 å­—/tokenï¼Œè‹±æ–‡ 4 å­—ç¬¦/tokenï¼‰"""
        chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', text))
        english_chars = len(re.findall(r'[a-zA-Z]', text))

        tokens = (chinese_chars / 1.5) + (english_chars / 4)
        return int(tokens)

    def truncate_to_tokens(self, text: str, max_tokens: int) -> str:
        """æˆªæ–­æ–‡æœ¬åˆ°æŒ‡å®š Token æ•°"""
        current_tokens = self.estimate_tokens(text)

        if current_tokens <= max_tokens:
            return text

        # æŒ‰æ¯”ä¾‹æˆªæ–­
        ratio = max_tokens / current_tokens
        target_length = int(len(text) * ratio * 0.95)  # ç•™ 5% ä½™é‡

        return text[:target_length] + "..."

    def build_core_context(self, chapter_num: int) -> Dict[str, Any]:
        """æ„å»ºæ ¸å¿ƒä¸Šä¸‹æ–‡ï¼ˆ1500 Tokenï¼‰"""
        core = {
            "current_outline": self._get_chapter_outline(chapter_num),
            "protagonist_brief": self._get_protagonist_brief(),
            "recent_summaries": self._get_recent_summaries(chapter_num, count=2)
        }

        return core

    def _get_chapter_outline(self, chapter_num: int) -> str:
        """è·å–å½“å‰ç« èŠ‚å¤§çº²ï¼ˆä»è¯¦ç»†å¤§çº²ä¸­æå–ï¼‰"""
        # æŸ¥æ‰¾åŒ…å«è¯¥ç« èŠ‚çš„å·
        for outline_file in self.outline_dir.glob("ç¬¬*å·-è¯¦ç»†å¤§çº².md"):
            with open(outline_file, 'r', encoding='utf-8') as f:
                content = f.read()

            # æŸ¥æ‰¾ç« èŠ‚æ ‡é¢˜ï¼ˆæ ¼å¼ï¼š#### ç¬¬ XXX ç« ï¼šæ ‡é¢˜ï¼‰
            pattern = f"#### ç¬¬ {chapter_num:03d} ç« ï¼š(.+?)(?=####|$)"
            match = re.search(pattern, content, re.DOTALL)

            if match:
                outline = match.group(0)
                return self.truncate_to_tokens(outline, 600)  # é™åˆ¶ 600 Token

        return f"[æœªæ‰¾åˆ°ç¬¬ {chapter_num} ç« å¤§çº²ï¼Œè¯·æ£€æŸ¥è¯¦ç»†å¤§çº²æ–‡ä»¶]"

    def _get_protagonist_brief(self) -> Dict[str, Any]:
        """è·å–ä¸»è§’å¡ï¼ˆç®€ç‰ˆï¼š400 Tokenï¼‰"""
        if not self.state:
            return {}

        protag_state = self.state.get("protagonist_state", {})

        brief = {
            "name": protag_state.get("name", "ä¸»è§’"),
            "power": protag_state.get("power", {}),
            "location": protag_state.get("location", {}).get("current", "æœªçŸ¥"),
            "golden_finger": protag_state.get("golden_finger", {}).get("name", "æ— ")
        }

        # è¯»å–ä¸»è§’å¡çš„"æ ¸å¿ƒæ€§æ ¼"ç« èŠ‚ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        protag_card_file = self.settings_dir / "ä¸»è§’å¡.md"
        if protag_card_file.exists():
            with open(protag_card_file, 'r', encoding='utf-8') as f:
                content = f.read()

            # æå–"æ€§æ ¼ç‰¹ç‚¹"ç« èŠ‚
            personality_match = re.search(r'## æ€§æ ¼ç‰¹ç‚¹\n\n(.+?)(?=\n##|$)', content, re.DOTALL)
            if personality_match:
                personality = personality_match.group(1).strip()
                brief["personality"] = self.truncate_to_tokens(personality, 200)

        return brief

    def _get_recent_summaries(self, chapter_num: int, count: int = 2) -> List[str]:
        """è·å–å‰ N ç« çš„æ‘˜è¦ï¼ˆæ¯ç«  200 å­—ï¼‰"""
        summaries = []

        for i in range(chapter_num - count, chapter_num):
            if i <= 0:
                continue

            chapter_file = self.chapters_dir / f"ç¬¬{i:04d}ç« .md"
            if not chapter_file.exists():
                continue

            with open(chapter_file, 'r', encoding='utf-8') as f:
                content = f.read()

            # æå–æ­£æ–‡ï¼ˆå»é™¤æ ‡é¢˜ã€å…ƒæ•°æ®ç­‰ï¼‰
            text_match = re.search(r'---\n\n(.+)', content, re.DOTALL)
            if text_match:
                text = text_match.group(1).strip()
            else:
                text = content

            # ç”Ÿæˆæ‘˜è¦ï¼ˆå–å‰ 200 å­—ï¼‰
            summary = text[:200] + "..."
            summaries.append(f"ç¬¬ {i} ç« æ‘˜è¦ï¼š{summary}")

        return summaries

    def build_scene_context(self, chapter_num: int, location: Optional[str] = None,
                           characters: Optional[List[str]] = None) -> Dict[str, Any]:
        """æ„å»ºåœºæ™¯ä¸Šä¸‹æ–‡ï¼ˆ1500 Tokenï¼‰"""

        # ç¡®å®šå½“å‰åœ°ç‚¹
        if not location and self.state:
            location = self.state.get("protagonist_state", {}).get("location", {}).get("current")

        scene = {
            "location_details": self._get_location_details(location) if location else None,
            "character_cards": self._get_character_cards(characters) if characters else [],
            "relevant_foreshadowing": self._get_relevant_foreshadowing(location, characters),
            "relevant_items": self._get_relevant_items()
        }

        return scene

    def _get_location_details(self, location: str) -> str:
        """è·å–åœ°ç‚¹è¯¦æƒ…ï¼ˆä» ä¸–ç•Œè§‚.md æå–ï¼‰"""
        worldview_file = self.settings_dir / "ä¸–ç•Œè§‚.md"

        if not worldview_file.exists():
            return f"[åœ°ç‚¹ï¼š{location}]ï¼ˆè¯¦æƒ…å¾…è¡¥å……ï¼‰"

        with open(worldview_file, 'r', encoding='utf-8') as f:
            content = f.read()

        # æŸ¥æ‰¾åœ°ç‚¹ç« èŠ‚ï¼ˆæ ¼å¼ï¼š### åœ°ç‚¹åï¼‰
        pattern = f"### {re.escape(location)}\n\n(.+?)(?=\n###|$)"
        match = re.search(pattern, content, re.DOTALL)

        if match:
            details = match.group(1).strip()
            return self.truncate_to_tokens(details, 400)  # é™åˆ¶ 400 Token

        return f"[åœ°ç‚¹ï¼š{location}]ï¼ˆä¸–ç•Œè§‚.md ä¸­æœªæ‰¾åˆ°è¯¦æƒ…ï¼‰"

    def _get_character_cards(self, characters: List[str]) -> List[Dict[str, str]]:
        """è·å–è§’è‰²å¡ï¼ˆå®Œæ•´ç‰ˆï¼Œæœ€å¤š 5 ä¸ªï¼Œæ¯ä¸ª 200 Tokenï¼‰"""
        cards = []

        for char_name in characters[:5]:  # æœ€å¤š 5 ä¸ª
            # åœ¨è§’è‰²åº“ä¸­æŸ¥æ‰¾
            for category in ["ä¸»è¦è§’è‰²", "æ¬¡è¦è§’è‰²", "åæ´¾è§’è‰²"]:
                char_file = self.settings_dir / f"è§’è‰²åº“/{category}/{char_name}.md"

                if char_file.exists():
                    with open(char_file, 'r', encoding='utf-8') as f:
                        content = f.read()

                    # æˆªæ–­åˆ° 200 Token
                    truncated = self.truncate_to_tokens(content, 200)
                    cards.append({
                        "name": char_name,
                        "content": truncated
                    })
                    break

        return cards

    def _get_relevant_foreshadowing(self, location: Optional[str],
                                   characters: Optional[List[str]]) -> List[Dict[str, str]]:
        """è·å–ç›¸å…³ä¼ç¬”ï¼ˆæœªå›æ”¶ ä¸” æ¶‰åŠå½“å‰åœ°ç‚¹/è§’è‰²ï¼‰"""
        if not self.state:
            return []

        all_foreshadowing = self.state.get("plot_threads", {}).get("foreshadowing", [])
        relevant = []

        for item in all_foreshadowing:
            if item.get("status") != "æœªå›æ”¶":
                continue

            content = item.get("content", "")

            # æ£€æŸ¥æ˜¯å¦ä¸å½“å‰åœ°ç‚¹/è§’è‰²ç›¸å…³
            is_relevant = False

            if location and location in content:
                is_relevant = True

            if characters:
                for char in characters:
                    if char in content:
                        is_relevant = True
                        break

            if is_relevant:
                relevant.append(item)

        return relevant[:3]  # æœ€å¤š 3 æ¡

    def _get_relevant_items(self) -> List[str]:
        """è·å–ç›¸å…³ç‰©å“/æ‹›å¼ï¼ˆä¸»è§’å½“å‰æ‹¥æœ‰ï¼‰"""
        if not self.state:
            return []

        # ä» state.json çš„ entities ä¸­æå–ä¸»è§’æ‹¥æœ‰çš„ç‰©å“
        entities = self.state.get("entities", {})
        items = entities.get("items", [])

        # ç®€åŒ–ï¼šåªè¿”å›ç‰©å“åç§°åˆ—è¡¨
        return [item.get("name") for item in items[:5]]  # æœ€å¤š 5 ä¸ª

    def build_global_overview(self) -> Dict[str, str]:
        """æ„å»ºå…¨å±€æ¦‚è§ˆï¼ˆ500 Tokenï¼‰"""
        overview = {
            "worldview_skeleton": self._get_worldview_skeleton(),
            "power_system_brief": self._get_power_system_brief(),
            "urgent_foreshadowing": self._get_urgent_foreshadowing()
        }

        return overview

    def _get_worldview_skeleton(self) -> str:
        """è·å–ä¸–ç•Œè§‚éª¨æ¶ï¼ˆ200 Tokenï¼‰"""
        worldview_file = self.settings_dir / "ä¸–ç•Œè§‚.md"

        if not worldview_file.exists():
            return "[ä¸–ç•Œè§‚éª¨æ¶å¾…è¡¥å……]"

        with open(worldview_file, 'r', encoding='utf-8') as f:
            content = f.read()

        # æå–"åŠ¿åŠ›"ç« èŠ‚çš„æ ‡é¢˜åˆ—è¡¨
        factions = re.findall(r'### (.+)', content)

        skeleton = "åŠ¿åŠ›ï¼š" + "ã€".join(factions[:10])  # æœ€å¤š 10 ä¸ª
        return self.truncate_to_tokens(skeleton, 200)

    def _get_power_system_brief(self) -> str:
        """è·å–åŠ›é‡ä½“ç³»ï¼ˆ200 Tokenï¼‰"""
        power_file = self.settings_dir / "åŠ›é‡ä½“ç³».md"

        if not power_file.exists():
            return "[åŠ›é‡ä½“ç³»å¾…è¡¥å……]"

        with open(power_file, 'r', encoding='utf-8') as f:
            content = f.read()

        # æå–"å¢ƒç•Œåˆ’åˆ†"ç« èŠ‚
        realm_match = re.search(r'## å¢ƒç•Œåˆ’åˆ†\n\n(.+?)(?=\n##|$)', content, re.DOTALL)

        if realm_match:
            realms = realm_match.group(1).strip()
            return self.truncate_to_tokens(realms, 200)

        return "[å¢ƒç•Œåˆ’åˆ†å¾…è¡¥å……]"

    def _get_urgent_foreshadowing(self) -> List[str]:
        """è·å–ç´§æ€¥ä¼ç¬”ï¼ˆæœªå›æ”¶ ä¸” å·²åŸ‹è¶…è¿‡ 100 ç« ï¼‰"""
        if not self.state:
            return []

        current_chapter = self.state.get("progress", {}).get("current_chapter", 0)
        all_foreshadowing = self.state.get("plot_threads", {}).get("foreshadowing", [])

        urgent = []

        for item in all_foreshadowing:
            if item.get("status") != "æœªå›æ”¶":
                continue

            # è®¡ç®—å·²åŸ‹ç« èŠ‚æ•°ï¼ˆç²—ç•¥ï¼šå‡è®¾æ¯ç« å¯¹åº” 1 ä¸ªç« èŠ‚å·å¢é‡ï¼‰
            # å®é™…é¡¹ç›®ä¸­åº”è¯¥è®°å½•"åŸ‹è®¾ç« èŠ‚å·"
            # è¿™é‡Œç®€åŒ–ï¼šå¦‚æœ added_at è·ç¦»ç°åœ¨è¶…è¿‡ 100 å¤©ï¼Œè§†ä¸ºç´§æ€¥

            content = item.get("content", "")
            urgent.append(f"âš ï¸ {content}")

        return urgent[:3]  # æœ€å¤š 3 æ¡

    def build_context(self, chapter_num: int, location: Optional[str] = None,
                     characters: Optional[List[str]] = None) -> Dict[str, Any]:
        """æ„å»ºå®Œæ•´ä¸Šä¸‹æ–‡"""

        context = {
            "chapter": chapter_num,
            "core_context": self.build_core_context(chapter_num),
            "scene_context": self.build_scene_context(chapter_num, location, characters),
            "global_overview": self.build_global_overview(),
            "metadata": {
                "token_usage": {}
            }
        }

        # ä¼°ç®— Token æ¶ˆè€—
        core_tokens = self.estimate_tokens(json.dumps(context["core_context"], ensure_ascii=False))
        scene_tokens = self.estimate_tokens(json.dumps(context["scene_context"], ensure_ascii=False))
        global_tokens = self.estimate_tokens(json.dumps(context["global_overview"], ensure_ascii=False))

        context["metadata"]["token_usage"] = {
            "core": core_tokens,
            "scene": scene_tokens,
            "global": global_tokens,
            "total": core_tokens + scene_tokens + global_tokens
        }

        return context

    def save_context(self, context: Dict[str, Any], output_file: str):
        """ä¿å­˜ä¸Šä¸‹æ–‡åˆ°æ–‡ä»¶"""
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(context, f, ensure_ascii=False, indent=2)

        print(f"âœ… ä¸Šä¸‹æ–‡å·²ä¿å­˜: {output_file}")
        print(f"\nğŸ“Š Token ä½¿ç”¨æƒ…å†µï¼š")
        usage = context["metadata"]["token_usage"]
        print(f"  æ ¸å¿ƒä¸Šä¸‹æ–‡: {usage['core']} Token")
        print(f"  åœºæ™¯ä¸Šä¸‹æ–‡: {usage['scene']} Token")
        print(f"  å…¨å±€æ¦‚è§ˆ: {usage['global']} Token")
        print(f"  æ€»è®¡: {usage['total']} Token")

        # èŠ‚çœç™¾åˆ†æ¯”ï¼ˆç›¸æ¯”å…¨é‡åŠ è½½ 50,000 Tokenï¼‰
        savings = (1 - usage['total'] / 50000) * 100
        print(f"\nğŸ’° ç›¸æ¯”å…¨é‡åŠ è½½èŠ‚çœ: {savings:.1f}%")

def main():
    import argparse

    parser = argparse.ArgumentParser(
        description="ä¸Šä¸‹æ–‡æ»‘åŠ¨çª—å£ç®¡ç†å™¨",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ï¼š
  # ä¸ºç¬¬ 45 ç« æ„å»ºä¸Šä¸‹æ–‡
  python context_manager.py --chapter 45 --output .webnovel/context_cache.json

  # æŒ‡å®šåœ°ç‚¹å’Œè§’è‰²
  python context_manager.py --chapter 45 --location "è¡€ç…ç§˜å¢ƒ" --characters "æé›ª,è¡€ç…é—¨ä¸»"

  # Dry-run æ¨¡å¼ï¼ˆé¢„è§ˆ Token æ¶ˆè€—ï¼‰
  python context_manager.py --chapter 45 --dry-run
        """
    )

    parser.add_argument('--chapter', type=int, required=True, help='ç« èŠ‚å·')
    parser.add_argument('--location', help='ä¸»è§’æ‰€åœ¨åœ°ç‚¹ï¼ˆå¯é€‰ï¼‰')
    parser.add_argument('--characters', help='å‡ºåœºè§’è‰²åˆ—è¡¨ï¼ˆé€—å·åˆ†éš”ï¼‰')
    parser.add_argument('--output', default='.webnovel/context_cache.json', help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--project-root', default='.', help='é¡¹ç›®æ ¹ç›®å½•')
    parser.add_argument('--dry-run', action='store_true', help='é¢„è§ˆæ¨¡å¼ï¼Œä¸ä¿å­˜æ–‡ä»¶')

    args = parser.parse_args()

    # è§£æè§’è‰²åˆ—è¡¨
    characters = None
    if args.characters:
        characters = [c.strip() for c in args.characters.split(',')]

    # åˆ›å»ºç®¡ç†å™¨
    manager = ContextManager(args.project_root)

    # åŠ è½½çŠ¶æ€
    if not manager.load_state():
        sys.exit(1)

    print(f"ğŸ“– æ­£åœ¨ä¸ºç¬¬ {args.chapter} ç« æ„å»ºä¸Šä¸‹æ–‡...")

    # æ„å»ºä¸Šä¸‹æ–‡
    context = manager.build_context(args.chapter, args.location, characters)

    # ä¿å­˜æˆ–é¢„è§ˆ
    if args.dry_run:
        print("\nâš ï¸  Dry-run æ¨¡å¼ï¼Œä¸ä¿å­˜æ–‡ä»¶")
        print("\nğŸ“„ ä¸Šä¸‹æ–‡é¢„è§ˆï¼š")
        print(json.dumps(context, ensure_ascii=False, indent=2))
    else:
        manager.save_context(context, args.output)

if __name__ == "__main__":
    main()
